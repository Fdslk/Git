---
title: 文本表示
grammar_cjkRuby: true
---
*文本表示和特征选择*
1.空间向量模型![enter description here][1]
特征：指出现在文档啊中并能表示该文档特点的基本语言单位（如英文等西方语言中的单词，汉语、日语等语言中的字和词、词组）；	
特征项权重：指特征项能够代表文档D能力的大小，它体现了该特征项在文档D中的重要程度。
![enter description here][2]
表示为文档向量的线性表的存储方式和链表的存储方式
![enter description here][3]
使用链表存储文本向量，节约空间，因为在某个维度下可能有多个的0的值
相似度S的计算：
曼哈顿距离、欧几里得距离、向量内积、余弦相似度。后面两者就是两者的夹角越小相似度越高。
![enter description here][4]w表示每个特征项的权重，n表示总数，D表示不同文档

文本预处理：1.字符编码转换2.中文文本分词（最重要）3.停用词过滤（停用词表中主要有数字，西方语言中的字母，还有大量的中英日俄等语言的常用词，这些词一般都是虚词、量词等，他们几乎出现在所有类别中的文档中，因而不具有任何类别信息，不能作为特征使用。）

特征权值计算：
![enter description here][5]
IDF inverse Document Frequency（逆文档频率）

文本间的相似度计算：
使用余弦相似度来计算待分类文档和训练集中文档间的相似度值
![enter description here][6]

特征选择算法：文档频率（Document Frequency）、互信息（Mutual Information）、信息增益（Information Gain）、X^2统计量
1.提高分类效率、2.是文本之间的相似度更加准确，既提高语义上相关文本之间的相似度同时降低语义上不相关文本之间的相似度3.提高分类器的推广能力

*文本分类算法*
*1.基于统计的的方法：*
简单贝叶斯，K最近邻方法（KNN），类中心向量，回归模型，支持向量机（SVM），最大熵模型
*2基于连接的方法：* 人工神经网络
*3.基于规则的发方法：* 决策树

主要使用SVM， 和KNN
SVM该方法是从可分情况下的最优分类面提出的![enter description here][7]
过两类样本中离分类面最近的店且平行于最优分类面的超平面H1，H2上的训练样本就是上式中使等号成立的那些样本，它们叫做支持向量，因为它们职称了最优分类面。
对于非线性问题，输入空间可以通过非线性变换化为某个高维空间中的线性问题，在变换空间求最优分类面。这种变换可能比较复杂,特别是随着输入空间样本数的增大,特征空间的维数很快变得不可计算,这时就需要核函数将特征映射到高维空间定义非线性映射中“令将输入空间的样本映射到高维特征空间中,当在中构造最优超平面时,训练算法仅使用空间中的内积。
![enter description here][8]


KNN算法：
![enter description here][9]
当出现了两都是邻近的最大值得数值时，需要使用相似度辅助KNN分类，当有相同的时候就取相似度最大的那个类最为文档最后被判为的类。


  [1]: ./images/1486354227897.jpg "1486354227897.jpg"
  [2]: ./images/1486354891900.jpg "1486354891900.jpg"
  [3]: ./images/1486354917423.jpg "1486354917423.jpg"
  [4]: ./images/1486355409422.jpg "1486355409422.jpg"
  [5]: ./images/1486357447663.jpg "1486357447663.jpg"
  [6]: ./images/1486358118194.jpg "1486358118194.jpg"
  [7]: ./images/1486440002047.jpg "1486440002047.jpg"
  [8]: ./images/1486444006934.jpg "1486444006934.jpg"
  [9]: ./images/1486445233263.jpg "1486445233263.jpg"